{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8eba03d-6afa-41c0-92c1-0d0253b2d4f4",
   "metadata": {},
   "source": [
    "### Esta sección aborda la tarea más compleja de la estimación de pose, desde la definición conceptual de un esqueleto anatómico para salmones hasta la implementación del código y la extracción de métricas cinemáticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b10cc56-5364-402a-8e14-d164df6bdb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d739f44d-10d5-400a-a7ed-e91b70c9500b",
   "metadata": {},
   "source": [
    " El formato de salida de COCO JSON debe ser convertido al formato de texto requerido por YOLOv8-Pose. Cada línea en el archivo .txt de una imagen debe seguir la estructura: <class-index> <box_x_center> <box_y_center> <box_width> <box_height> <kpt1_x> <kpt1_y> <kpt2_x> <kpt2_y>... <kptn_x> <kptn_y>. Todas las coordenadas (caja y puntos clave) deben estar normalizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a04cea-bd63-46a9-b5a3-1ce88380189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ejemplo de uso:\n",
    "# La estructura de carpetas y el archivo data.yaml son análogos al caso de segmentación.\n",
    "# convert_coco_kpts_to_yolo_pose('/path/to/dataset/annotations/person_keypoints_train.json', '/path/to/yolo_pose_dataset/train/')\n",
    "\n",
    "\n",
    "def convert_coco_kpts_to_yolo_pose(coco_json_path, save_dir, use_segmentation_for_bbox=False):\n",
    "    \"\"\"\n",
    "    Convierte anotaciones de pose en formato COCO JSON al formato YOLOv8-Pose.\n",
    "    \"\"\"\n",
    "    save_path = Path(save_dir)\n",
    "    labels_path = save_path / 'labels'\n",
    "    labels_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(coco_json_path, 'r') as f:\n",
    "        data = json.load(data)\n",
    "\n",
    "    images_info = {img['id']: {'file_name': img['file_name'], 'height': img['height'], 'width': img['width']} for img in data['images']}\n",
    "    categories = {cat['id']: i for i, cat in enumerate(data['categories'])}\n",
    "    num_kpts = len(data['categories']['keypoints'])\n",
    "\n",
    "    annotations_by_image = {}\n",
    "    for ann in data['annotations']:\n",
    "        img_id = ann['image_id']\n",
    "        if img_id not in annotations_by_image:\n",
    "            annotations_by_image[img_id] =\n",
    "        annotations_by_image[img_id].append(ann)\n",
    "\n",
    "    print(\"Iniciando conversión de anotaciones de pose...\")\n",
    "    for img_id, anns in tqdm(annotations_by_image.items()):\n",
    "        img_info = images_info[img_id]\n",
    "        img_h, img_w = img_info['height'], img_info['width']\n",
    "        \n",
    "        if img_h == 0 or img_w == 0:\n",
    "            continue\n",
    "\n",
    "        label_name = Path(img_info['file_name']).stem + '.txt'\n",
    "        label_path = labels_path / label_name\n",
    "\n",
    "        with open(label_path, 'w') as f:\n",
    "            for ann in anns:\n",
    "                if 'keypoints' not in ann or ann['num_keypoints'] == 0:\n",
    "                    continue\n",
    "\n",
    "                class_index = categories[ann['category_id']]\n",
    "                \n",
    "                # Bounding box\n",
    "                x, y, w, h = ann['bbox']\n",
    "                xc = (x + w / 2) / img_w\n",
    "                yc = (y + h / 2) / img_h\n",
    "                wn = w / img_w\n",
    "                hn = h / img_h\n",
    "\n",
    "                line_parts = [str(class_index), str(xc), str(yc), str(wn), str(hn)]\n",
    "\n",
    "                # Keypoints\n",
    "                kpts = ann['keypoints']\n",
    "                for i in range(num_kpts):\n",
    "                    kpt_x = kpts[i * 3]\n",
    "                    kpt_y = kpts[i * 3 + 1]\n",
    "                    vis = kpts[i * 3 + 2]\n",
    "\n",
    "                    # YOLO format no usa la bandera de visibilidad directamente,\n",
    "                    # pero los puntos no visibles (v=0) se ponen en (0,0)\n",
    "                    if vis == 0:\n",
    "                        nx, ny = 0, 0\n",
    "                    else:\n",
    "                        nx = kpt_x / img_w\n",
    "                        ny = kpt_y / img_h\n",
    "                    \n",
    "                    line_parts.extend([str(nx), str(ny)])\n",
    "                \n",
    "                f.write(\" \".join(line_parts) + '\\n')\n",
    "    \n",
    "    print(f\"Conversión completada. Las etiquetas se guardaron en: {labels_path}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "57e0276c-53fe-4215-9e59-314b843e248b",
   "metadata": {},
   "source": [
    "el entrenamiento de un modelo de pose implica la optimización de una función de pérdida compuesta que incluye la pérdida de la caja delimitadora, la pérdida de clasificación de clase, y una pérdida específica para los puntos clave. Esta última a menudo combina una pérdida de \"objetividad\" (¿está el punto clave presente?) y una pérdida de localización (¿qué tan cerca está la predicción de la verdad fundamental?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc089c09-586e-458c-b73a-cedfe6f02a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar un modelo de estimación de pose pre-entrenado YOLOv8n-pose.pt\n",
    "model = YOLO('yolov8n-pose.pt')\n",
    "\n",
    "# Entrenar el modelo\n",
    "print(\"Iniciando el entrenamiento del modelo de estimación de pose...\")\n",
    "results = model.train(\n",
    "    data='path/to/salmon_pose_dataset/data.yaml',\n",
    "    epochs=150,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    patience=30,\n",
    "    name='yolov8n_salmon_pose'\n",
    ")\n",
    "print(\"Entrenamiento completado.\")\n",
    "print(f\"El mejor modelo se guardó en: {results.save_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
