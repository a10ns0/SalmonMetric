{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c9daf3b-3f46-4ea0-9c1b-621150519a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 游 Notebook: Entrenamiento de Modelo YOLOv8 Pose - Salmo Metrics\n",
    "# ============================================================\n",
    "# Proyecto: Estimaci칩n autom치tica de dimensiones de salmones\n",
    "# Autor: Alonso Castillo\n",
    "# Fecha: Octubre 2025\n",
    "# ------------------------------------------------------------\n",
    "# Este notebook entrena un modelo YOLOv8 pose (keypoints)\n",
    "# utilizando un dataset exportado desde CVAT en formato COCO Keypoints.\n",
    "# ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83fe884c-bca2-424a-9e4f-12f34ca9538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#librer칤as ---\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "from IPython.display import Image, display\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4779601-d363-4241-8c5f-2d92cc8fd88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convierte anotaciones de segmentaci칩n en formato COCO JSON al formato YOLOv8-Seg.\n",
    "# una carpeta 'labels' paralela.\n",
    "# Ejemplo de uso:\n",
    "# Asegurarse que las carpetas se encuentren as칤:\n",
    "#  salmon_segmentation_dataset/\n",
    "#   - images/\n",
    "#     - train/\n",
    "#       - img1.jpg\n",
    "#       -...\n",
    "#     - val/\n",
    "#       - imgN.jpg\n",
    "#       -...\n",
    "#   - annotations/\n",
    "#     - instances_train.json\n",
    "#     - instances_val.json\n",
    "\n",
    "# convert_coco_to_yolo_seg('/salmon_segmentation_dataset/annotations/instances_train.json', '/segmentation_yolo_dataset/train/')\n",
    "# convert_coco_to_yolo_seg('/salmon_segmentation_dataset/annotations/instances_val.json', '/segmentation_yolo_dataset/val/')\n",
    "\n",
    "def convert_coco_to_yolo_seg(coco_json_path, save_dir):\n",
    "\n",
    "    save_path = Path(save_dir)\n",
    "    labels_path = save_path / 'labels'\n",
    "    images_path = save_path / 'images'\n",
    "    labels_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(coco_json_path, 'r') as f:\n",
    "        data = json.load(data)\n",
    "\n",
    "    # Crear un mapeo de image_id a nombre de archivo y dimensiones\n",
    "    images_info = {img['id']: {'file_name': img['file_name'], 'height': img['height'], 'width': img['width']} for img in data['images']}\n",
    "    \n",
    "    # Crear un mapeo de category_id a class_index (asumiendo que los IDs de COCO no son necesariamente 0-indexados)\n",
    "    categories = {cat['id']: i for i, cat in enumerate(data['categories'])}\n",
    "\n",
    "    # Agrupar anotaciones por image_id\n",
    "    annotations_by_image = {}\n",
    "    for ann in data['annotations']:\n",
    "        img_id = ann['image_id']\n",
    "        if img_id not in annotations_by_image:\n",
    "            annotations_by_image[img_id] = []\n",
    "            annotations_by_image[img_id].append(ann)\n",
    "\n",
    "    print(\"Iniciando conversi칩n de anotaciones...\")\n",
    "    for img_id, anns in tqdm(annotations_by_image.items()):\n",
    "        img_info = images_info[img_id]\n",
    "        img_h, img_w = img_info['height'], img_info['width']\n",
    "        \n",
    "        # Validar que las dimensiones de la imagen son v치lidas\n",
    "        if img_h == 0 or img_w == 0:\n",
    "            print(f\"Advertencia: La imagen {img_info['file_name']} tiene dimensiones cero. Se omitir치.\")\n",
    "            continue\n",
    "\n",
    "        label_name = Path(img_info['file_name']).stem + '.txt'\n",
    "        label_path = labels_path / label_name\n",
    "\n",
    "        with open(label_path, 'w') as f:\n",
    "            for ann in anns:\n",
    "                # Validar que es una anotaci칩n de segmentaci칩n\n",
    "                if 'segmentation' not in ann or not ann['segmentation']:\n",
    "                    continue\n",
    "\n",
    "                class_index = categories[ann['category_id']]\n",
    "                \n",
    "                # El formato de segmentaci칩n de COCO puede tener m칰ltiples pol칤gonos para una instancia\n",
    "                for seg in ann['segmentation']:\n",
    "                    # Validar que el pol칤gono tiene al menos 3 v칠rtices\n",
    "                    if len(seg) < 6:\n",
    "                        print(f\"Advertencia: Pol칤gono inv치lido (menos de 3 v칠rtices) en {img_info['file_name']}. Se omitir치.\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Normalizar coordenadas\n",
    "                    normalized_coords = [] \n",
    "                    for i in range(0, len(seg), 2):\n",
    "                        x = seg[i] / img_w\n",
    "                        y = seg[i+1] / img_h\n",
    "                        normalized_coords.extend([x, y])\n",
    "                    \n",
    "                    # Escribir en el archivo de etiqueta\n",
    "                    line = f\"{class_index} \" + \" \".join(map(str, normalized_coords))\n",
    "                    f.write(line + '\\n')\n",
    "\n",
    "    print(f\"Conversi칩n completada. Las etiquetas se guardaron en: {labels_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20b589d-6339-411f-8dbf-4ab6c613a696",
   "metadata": {},
   "source": [
    "### Procesado de datos (normalizacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a000a13-05c9-4ecd-ad58-a404b5f9c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    " convert_coco_to_yolo_seg('/salmon_segmentation_dataset/annotations/instances_train.json', '/segmentation_yolo_dataset/train/')\n",
    " convert_coco_to_yolo_seg('/salmon_segmentation_dataset/annotations/instances_val.json', '/segmentation_yolo_dataset/val/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf67420-ce64-4b58-ab1e-5e17a9a09afe",
   "metadata": {},
   "source": [
    "## Cargar un modelo de segmentaci칩n pre-entrenado YOLOv8n-seg.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaa8dff7-bee1-4b7d-8add-b6638a3b80c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 'n' se refiere al modelo nano, el m치s peque침o y r치pido. \n",
    "# Se pueden usar otros tama침os como 's', 'm', 'l', 'x' para mayor precisi칩n a costa de velocidad.\n",
    "model = YOLO('yolov8n-seg.pt')  # Carga pesos pre-entrenados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60470b5e-3ea5-4347-88e6-087b787adb5a",
   "metadata": {},
   "source": [
    "## Entrenar el modelo con el conjunto de datos de salmones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f7a223-3ef9-413b-97d9-ff8ea660ba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Iniciando el entrenamiento del modelo de segmentaci칩n...\")\n",
    "results = model.train(\n",
    "    data='salmon_segmentation_dataset/data.yaml',\n",
    "    epochs=100,          # N칰mero de 칠pocas de entrenamiento\n",
    "    imgsz=640,           # Tama침o de imagen de entrada\n",
    "    batch=16,            # Tama침o del lote\n",
    "    patience=20,         # 칄pocas a esperar sin mejora antes de detener el entrenamiento\n",
    "    name='yolov8n_salmon_seg', # Nombre del experimento\n",
    "    # Par치metros de aumento de datos (data augmentation)\n",
    "    # Cruciales para la robustez en entornos subacu치ticos\n",
    "    hsv_h=0.015,  # Aumento de matriz\n",
    "    hsv_s=0.7,    # Aumento de saturaci칩n\n",
    "    hsv_v=0.4,    # Aumento de valor (brillo)\n",
    "    degrees=0.0,  # Rotaci칩n\n",
    "    translate=0.1,# Traslaci칩n\n",
    "    scale=0.5,    # Escala (zoom)\n",
    "    flipud=0.5,   # Flip vertical\n",
    "    mosaic=1.0,   # Aumento de mosaico\n",
    "    mixup=0.1     # Aumento de mixup\n",
    ")\n",
    "print(\"Entrenamiento completado.\")\n",
    "print(f\"El mejor modelo se guard칩 en: {results.save_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
